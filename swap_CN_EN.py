import copy as cp
import os
import csv
import json
import re
import tempfile
from typing import Dict, List, Any, Union
from pathlib import Path

# -------------------------- å…¨å±€ä¸´æ—¶æ–‡ä»¶/é‡å‘½åä»»åŠ¡ç®¡ç† --------------------------
# å­˜å‚¨æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶è·¯å¾„æ˜ å°„åˆ°åŸæ–‡ä»¶ï¼Œç”¨äºæ‰¹é‡æ›¿æ¢/æ¸…ç†
TEMP_FILES: Dict[str, str] = {}
# å­˜å‚¨é‡å‘½åä»»åŠ¡ï¼Œæ‰¹é‡æ‰§è¡Œ
RENAME_TASKS: List[tuple] = []

# -------------------------- ä¸´æ—¶æ–‡ä»¶æ“ä½œå‡½æ•° --------------------------
def create_temp_file(content: str, original_file_path: str) -> str:
    """
    åˆ›å»ºä¸´æ—¶æ–‡ä»¶ï¼ˆä¸åŸæ–‡ä»¶åŒç›®å½•ï¼‰ï¼Œè¿”å›ä¸´æ—¶æ–‡ä»¶è·¯å¾„
    :param content: è¦å†™å…¥ä¸´æ—¶æ–‡ä»¶çš„å†…å®¹
    :param original_file_path: åŸæ–‡ä»¶è·¯å¾„ï¼ˆç”¨äºç¡®å®šä¸´æ—¶æ–‡ä»¶ä½ç½®ï¼‰
    :return: ä¸´æ—¶æ–‡ä»¶ç»å¯¹è·¯å¾„
    """
    original_path = Path(original_file_path)
    # ç”Ÿæˆä¸´æ—¶æ–‡ä»¶ï¼ˆåç¼€.tmpï¼Œä¸åŸæ–‡ä»¶åŒç›®å½•ï¼‰
    temp_fd, temp_path = tempfile.mkstemp(
        suffix='.tmp',
        prefix=original_path.stem + '_',
        dir=str(original_path.parent)
    )
    # å†™å…¥å†…å®¹å¹¶å…³é—­æ–‡ä»¶å¥æŸ„ï¼ˆUTF-8ç¼–ç ï¼Œä¿ç•™ä¸­æ–‡ï¼‰
    with os.fdopen(temp_fd, 'w', encoding='utf-8') as f:
        f.write(content)
    # è®°å½•ä¸´æ—¶æ–‡ä»¶è·¯å¾„ -> åŸæ–‡ä»¶è·¯å¾„ æ˜ å°„ï¼ˆç”¨äºåŸå­æ›¿æ¢æ—¶æ¢å¤åŸå/æ‰©å±•åï¼‰
    TEMP_FILES[temp_path] = str(original_path)
    return temp_path

def write_to_temp_csv(rows: List[Dict[str, str]], original_file_path: str) -> str:
    """
    å°†CSVæ•°æ®å†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼ˆä¿ç•™ä¸­æ–‡é€—å·ï¼Œä»…å¤„ç†åŠè§’é€—é€—å·è½¬ä¹‰ï¼‰
    :param rows: CSVè¡Œæ•°æ®
    :param original_file_path: åŸæ–‡ä»¶è·¯å¾„
    :return: ä¸´æ—¶æ–‡ä»¶è·¯å¾„
    """
    if not rows:
        raise ValueError("æ— æ•°æ®å¯å†™å…¥ä¸´æ—¶CSVæ–‡ä»¶")
    # æ„å»ºCSVå†…å®¹
    fieldnames = list(rows[0].keys())
    csv_content = []
    csv_content.append(','.join(fieldnames))  # è¡¨å¤´ï¼ˆåŠè§’é€—å·åˆ†éš”ï¼‰
    for row in rows:
        escaped_row = []
        # ensure we iterate in header order so columns align
        for k in fieldnames:
            v = row.get(k, '')
            val_str = '' if v is None else str(v)
            # ä»…å¤„ç†CSVæ ‡å‡†è½¬ä¹‰ï¼šå«åŠè§’é€—å·/åŒå¼•å·/æ¢è¡Œç¬¦çš„å­—æ®µéœ€ç”¨åŒå¼•å·åŒ…è£¹
            if ',' in val_str or '"' in val_str or '\n' in val_str:
                val_str = val_str.replace('"', '""')  # åŒå¼•å·è½¬ä¹‰ä¸ºä¸¤ä¸ª
                val_str = f'"{val_str}"'  # åŒ…è£¹åŒå¼•å·
            # ä¸­æ–‡é€—å·ï¼ˆï¼Œï¼‰ä¸åšä»»ä½•å¤„ç†ï¼Œä¿ç•™ä¸ºå­—ç¬¦ä¸²å†…å®¹
            escaped_row.append(val_str)
        csv_content.append(','.join(escaped_row))  # åŠè§’é€—å·åˆ†éš”å­—æ®µ
    csv_content = '\n'.join(csv_content)
    # å†™å…¥ä¸´æ—¶æ–‡ä»¶
    return create_temp_file(csv_content, original_file_path)

def write_to_temp_json(data: Union[Dict[str, Any], List[Any]], original_file_path: str) -> str:
    """
    å°†JSONæ•°æ®å†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼ˆä¿ç•™ä¸­æ–‡é€—å·ï¼ŒUTF-8ç¼–ç ï¼‰
    :param data: JSONå­—å…¸/åˆ—è¡¨æ•°æ®
    :param original_file_path: åŸæ–‡ä»¶è·¯å¾„
    :return: ä¸´æ—¶æ–‡ä»¶è·¯å¾„
    """
    # å¢å¼ºç©ºæ•°æ®æ ¡éªŒï¼Œæ·»åŠ æ—¥å¿—æç¤ºå…·ä½“æ–‡ä»¶
    if data is None:
        raise ValueError(f"æ— æ•°æ®å¯å†™å…¥ä¸´æ—¶JSONæ–‡ä»¶ï¼ˆæ–‡ä»¶è·¯å¾„ï¼š{original_file_path}ï¼‰")
    # æ ¼å¼åŒ–JSONå†…å®¹ï¼ˆensure_ascii=Falseä¿ç•™ä¸­æ–‡ï¼Œindent=2ä¿æŒç¼©è¿›ï¼‰
    json_content = json.dumps(data, ensure_ascii=False, indent=2)
    # å†™å…¥ä¸´æ—¶æ–‡ä»¶
    return create_temp_file(json_content, original_file_path)

def batch_replace_original_files() -> None:
    """æ‰¹é‡å°†ä¸´æ—¶æ–‡ä»¶æ›¿æ¢ä¸ºåŸæ–‡ä»¶ï¼ˆåŸå­æ“ä½œï¼Œè·¨å¹³å°å…¼å®¹ï¼‰"""
    # iterate over a snapshot because we'll modify TEMP_FILES inside loop
    for temp_path, original_path in list(TEMP_FILES.items()):
        try:
            if os.path.exists(temp_path) and os.path.exists(original_path):
                # ä½¿ç”¨os.replaceä¿è¯åŸå­æ›¿æ¢ï¼ˆè·¨å¹³å°ï¼Œé¿å…æ–‡ä»¶æŸåï¼‰
                os.replace(temp_path, original_path)
                print(f"âœ… åŸå­æ›¿æ¢å®Œæˆï¼š{original_path} â† {temp_path}")
            elif os.path.exists(temp_path) and not os.path.exists(original_path):
                # åŸæ–‡ä»¶ä¸å­˜åœ¨ï¼Œç›´æ¥é‡å‘½åä¸´æ—¶æ–‡ä»¶ä¸ºåŸæ–‡ä»¶
                os.rename(temp_path, original_path)
                print(f"âœ… é‡å‘½åä¸´æ—¶æ–‡ä»¶ä¸ºåŸæ–‡ä»¶ï¼š{temp_path} â†’ {original_path}")
            else:
                # temp file missing or both missing
                print(f"âš ï¸ ä¸´æ—¶æ–‡ä»¶æˆ–åŸæ–‡ä»¶ä¸å­˜åœ¨ï¼š{temp_path} / {original_path}")
        finally:
            # æ— è®ºæˆåŠŸä¸å¦ï¼Œç§»é™¤æ˜ å°„ä»¥é¿å…é‡å¤å¤„ç†
            TEMP_FILES.pop(temp_path, None)

def clean_temp_files() -> None:
    """æ¸…ç†æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶ï¼Œé¿å…æ®‹ç•™"""
    for temp_path in list(TEMP_FILES.keys()):
        if os.path.exists(temp_path):
            try:
                os.remove(temp_path)
                print(f"ğŸ—‘ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼š{temp_path}")
            except Exception as e:
                print(f"âš ï¸ æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥ {temp_path}ï¼š{e}")
        # ç§»é™¤æ˜ å°„
        TEMP_FILES.pop(temp_path, None)
    # æ¸…ç©ºä¸´æ—¶æ–‡ä»¶æ˜ å°„è¡¨
    TEMP_FILES.clear()

# -------------------------- é€šç”¨å·¥å…·å‡½æ•° --------------------------
def clean_json_content(raw_content: str) -> str:
    """
    æ¸…ç†JSONå†…å®¹ï¼ˆä¿ç•™ä¸­æ–‡é€—å·ï¼Œä»…å¤„ç†è¯­æ³•çº§é—®é¢˜ï¼‰ï¼š
    - ç§»é™¤ä¸å¯è§æ§åˆ¶å­—ç¬¦
    - ç»Ÿä¸€æ¢è¡Œ
    - ç§»é™¤ BOM
    - ç§»é™¤è¡Œå†…/è¡Œå°¾çš„ # æ³¨é‡Šï¼ˆä½†ä¿ç•™å­—ç¬¦ä¸²å†…çš„ #ï¼‰
    - ç§»é™¤æœ«å°¾å¤šä½™çš„åŠè§’é€—å·
    """
    # æ­¥éª¤1ï¼šç§»é™¤ä¸å¯è§æ§åˆ¶å­—ç¬¦ï¼ˆé¿å…å¹²æ‰°è§£æï¼Œä¸ç¢°ä¸­æ–‡é€—å·ï¼‰
    control_chars = [
        '\u200b', '\u200c', '\u200d',  # é›¶å®½ç©ºæ ¼/è¿æ¥ç¬¦
        '\x00', '\x01', '\x02', '\x03', '\x04', '\x05',  # ç©ºå­—ç¬¦/æ§åˆ¶å­—ç¬¦
        '\v', '\f', '\x1c', '\x1d', '\x1e', '\x1f'  # å‚ç›´åˆ¶è¡¨ç¬¦/æ¢é¡µç¬¦
    ]
    for char in control_chars:
        raw_content = raw_content.replace(char, '')

    # æ­¥éª¤2ï¼šç»Ÿä¸€æ¢è¡Œç¬¦ä¸º\n
    raw_content = raw_content.replace('\r\n', '\n').replace('\r', '\n')

    # æ­¥éª¤3ï¼šç§»é™¤UTF-8 BOMå¤´
    if raw_content.startswith('\ufeff'):
        raw_content = raw_content.lstrip('\ufeff')

    # æ­¥éª¤4ï¼šæŒ‰å­—ç¬¦éå†ç§»é™¤ # æ³¨é‡Šï¼Œä½†ä¿ç•™å­—ç¬¦ä¸²å†…çš„å†…å®¹
    out_chars: List[str] = []
    in_string = False
    string_quote = ''
    escape = False
    i = 0
    length = len(raw_content)
    while i < length:
        ch = raw_content[i]
        if escape:
            # previous was backslash, so this char is escaped inside string
            out_chars.append(ch)
            escape = False
            i += 1
            continue
        if in_string:
            if ch == '\\':
                # start escape sequence
                out_chars.append(ch)
                escape = True
                i += 1
                continue
            out_chars.append(ch)
            if ch == string_quote:
                in_string = False
                string_quote = ''
            i += 1
            continue
        # not in string
        if ch == '"' or ch == "'":
            in_string = True
            string_quote = ch
            out_chars.append(ch)
            i += 1
            continue
        if ch == '#':
            # skip until newline (remove the comment). keep the newline if present
            # advance i to next newline or EOF
            while i < length and raw_content[i] != '\n':
                i += 1
            # if newline exists, append it to preserve line breaks
            if i < length and raw_content[i] == '\n':
                out_chars.append('\n')
                i += 1
            continue
        # normal char outside string
        out_chars.append(ch)
        i += 1

    clean_content = ''.join(out_chars)

    # æ­¥éª¤5ï¼šç§»é™¤æœ«å°¾å¤šä½™åŠè§’é€—å·ï¼ˆåœ¨ ] æˆ– } ä¹‹å‰çš„é€—å·ï¼‰
    # ä½¿ç”¨æ­£åˆ™å»é™¤é€—å·åé¢åªè·Ÿç©ºç™½å†è·Ÿ ] æˆ– }
    clean_content = re.sub(r',\s*(?=[\]}])', '', clean_content)

    # æœ€åå»é™¤å¤šä½™ç©ºè¡Œå¹¶å³ä¾§ç©ºç™½
    lines = [ln.rstrip() for ln in clean_content.split('\n') if ln.strip() != '']
    return '\n'.join(lines)

def read_json_safely(file_path: str) -> Union[Dict[str, Any], List[Any]]:
    """
    å®‰å…¨è¯»å–JSONæ–‡ä»¶ï¼š
    1. ä¿ç•™å­—ç¬¦ä¸²å†…çš„ä¸­æ–‡é€—å·ï¼ˆï¼Œï¼‰
    2. è‡ªåŠ¨å¤„ç†UTF-8 BOMå¤´
    3. æç¤ºè¯­æ³•ä½ç½®çš„ä¸­æ–‡é€—å·é”™è¯¯
    4. æ–°å¢ï¼šç©ºæ•°æ®æ£€æµ‹å¹¶æç¤º
    """
    try:
        # ç”¨utf-8-sigç¼–ç è¯»å–ï¼Œè‡ªåŠ¨è¯†åˆ«å¹¶ç§»é™¤BOMå¤´
        with open(file_path, 'r', encoding='utf-8-sig') as f:
            raw_content = f.read()
        raw_content = raw_content.strip()

        # æ£€æµ‹ç©ºæ–‡ä»¶
        if not raw_content:
            raise ValueError(f"JSONæ–‡ä»¶å†…å®¹ä¸ºç©ºï¼š{file_path}")

        # æ¸…ç†æ³¨é‡Š/å¤šä½™åŠè§’é€—å·ï¼Œä¿ç•™ä¸­æ–‡é€—å·
        clean_content = clean_json_content(raw_content)

        # å†æ¬¡æ£€æµ‹æ¸…ç†åçš„æ•°æ®æ˜¯å¦ä¸ºç©º
        if not clean_content:
            raise ValueError(f"JSONæ–‡ä»¶æ¸…ç†åæ— æœ‰æ•ˆå†…å®¹ï¼š{file_path}")

        # è§£æJSON
        data = json.loads(clean_content)

        # æ£€æµ‹è§£æåçš„æ•°æ®æ˜¯å¦ä¸ºç©º
        if data is None or data == {} or data == []:
            raise ValueError(f"JSONæ–‡ä»¶è§£æåä¸ºç©ºï¼ˆç©ºå­—å…¸/åˆ—è¡¨ï¼‰ï¼š{file_path}")

        print(f"âœ… æˆåŠŸè¯»å–JSONæ–‡ä»¶ï¼ˆæœ‰æ•ˆæ•°æ®ï¼‰ï¼š{file_path}")
        return data

    except FileNotFoundError:
        raise
    except json.JSONDecodeError as e:
        error_msg = f"\nâŒ JSONè§£æé”™è¯¯ï¼ˆæ–‡ä»¶ï¼š{file_path}ï¼‰ï¼š{e}\n"
        error_msg += "âš ï¸ å¯èƒ½åŸå› ï¼š\n"
        error_msg += "  1. ä¸­æ–‡é€—å·ï¼ˆï¼Œï¼‰å‡ºç°åœ¨JSONè¯­æ³•ä½ç½®ï¼ˆå¦‚åˆ†éš”ç¬¦ï¼‰ï¼Œè¯·æ”¹ä¸ºåŠè§’é€—å·ï¼ˆ,ï¼‰ï¼›\n"
        error_msg += "  2. å­—ç¬¦ä¸²å†…çš„ä¸­æ–‡é€—å·æ— éœ€ä¿®æ”¹ï¼ˆå¦‚\"desc\": \"æµ‹è¯•ï¼Œå†…å®¹\"æ˜¯åˆæ³•çš„ï¼‰ã€‚\n"
        print(error_msg)
        # æ‰“å°é”™è¯¯ä½ç½®é™„è¿‘å†…å®¹ï¼Œä¾¿äºå®šä½é—®é¢˜
        error_range = clean_content[max(0, e.pos-10):e.pos+10] if 'clean_content' in locals() else "æ— æœ‰æ•ˆå†…å®¹"
        print(f"ğŸ“Œ é”™è¯¯ä½ç½®é™„è¿‘å†…å®¹ï¼š{repr(error_range)}")
        raise
    except Exception as e:
        print(f"\nâŒ è¯»å–JSONæ–‡ä»¶å¤±è´¥ï¼ˆæ–‡ä»¶ï¼š{file_path}ï¼‰ï¼š{e}")
        raise

def get_abs_file_path(relative_path: str) -> str:
    """è·å–è„šæœ¬æ‰€åœ¨ç›®å½•çš„ç»å¯¹è·¯å¾„ï¼Œè§£å†³ç›¸å¯¹è·¯å¾„é—®é¢˜"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    return os.path.join(script_dir, relative_path)

# -------------------------- CSVæ–‡ä»¶äº¤æ¢é€»è¾‘ --------------------------
def swap_file_csv(file_path: str, file_name_without_extension: str, swap_fields: list) -> None:
    """
    å¤„ç†CSVæ–‡ä»¶äº¤æ¢ï¼ˆä»…å†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼Œä¸ç«‹å³æ›¿æ¢åŸæ–‡ä»¶ï¼‰ï¼š
    1. ä¿ç•™å­—æ®µå†…çš„ä¸­æ–‡é€—å·
    2. ä»…äº¤æ¢æŒ‡å®šå­—æ®µçš„å€¼
    """
    # åˆå§‹åŒ–æ•°æ®å­˜å‚¨
    dict_rows_now: List[Dict[str, str]] = []
    dict_rows_other: List[Dict[str, str]] = []
    EN_to_CN = False  # é»˜è®¤ï¼šCN -> EN

    # å¤„ç†è·¯å¾„
    abs_file_path = get_abs_file_path(file_path)
    script_dir = os.path.dirname(abs_file_path)
    file_ext = os.path.splitext(abs_file_path)[1]  # è·å–æ–‡ä»¶åç¼€ï¼ˆ.csvï¼‰

    # æ„å»ºEN/CNæ–‡ä»¶è·¯å¾„
    en_file_name = f"{file_name_without_extension}_EN{file_ext}"
    cn_file_name = f"{file_name_without_extension}_CN{file_ext}"
    abs_path_en = os.path.join(script_dir, en_file_name)
    abs_path_cn = os.path.join(script_dir, cn_file_name)

    # éªŒè¯è¾“å…¥è·¯å¾„
    if file_name_without_extension in abs_file_path:
        abs_path_en = abs_file_path.replace(file_name_without_extension, f"{file_name_without_extension}_EN")
        abs_path_cn = abs_file_path.replace(file_name_without_extension, f"{file_name_without_extension}_CN")
    assert abs_file_path != abs_path_en, f"æ–‡ä»¶è·¯å¾„/åç§°è¾“å…¥é”™è¯¯ï¼š{abs_file_path} vs {abs_path_en}"

    # è¯»å–ä¸»æ–‡ä»¶ï¼ˆå¤„ç†#æ³¨é‡Šè¡Œï¼‰
    try:
        with open(abs_file_path, 'r', encoding='utf-8') as f:
            csv_reader = csv.DictReader(f)
            for row in csv_reader:
                row_id = row.get('id', '').strip()
                if not row_id or row_id.startswith('#'):
                    dict_rows_now.append(row)  # ä¿ç•™æ³¨é‡Šè¡Œï¼Œä¸å‚ä¸äº¤æ¢
                    continue
                dict_rows_now.append(row)
        print(f"ğŸ“„ æˆåŠŸåŠ è½½ä¸»æ–‡ä»¶ï¼š{abs_file_path}")

        # å°è¯•è¯»å–ENæ–‡ä»¶
        with open(abs_path_en, 'r', encoding='utf-8') as f:
            csv_reader = csv.DictReader(f)
            for row in csv_reader:
                row_id = row.get('id', '').strip()
                if not row_id or row_id.startswith('#'):
                    dict_rows_other.append(row)
                    continue
                dict_rows_other.append(row)
        print(f"ğŸ“„ æˆåŠŸåŠ è½½ENæ–‡ä»¶ï¼š{abs_path_en}")

    except FileNotFoundError as e:
        # ENæ–‡ä»¶ä¸å­˜åœ¨ï¼Œåˆ‡æ¢ä¸ºEN -> CNæ¨¡å¼
        if en_file_name in str(e):
            EN_to_CN = True
            try:
                with open(abs_path_cn, 'r', encoding='utf-8') as f:
                    csv_reader = csv.DictReader(f)
                    for row in csv_reader:
                        row_id = row.get('id', '').strip()
                        if not row_id or row_id.startswith('#'):
                            dict_rows_other.append(row)
                            continue
                        dict_rows_other.append(row)
                print(f"ğŸ“„ ENæ–‡ä»¶ä¸å­˜åœ¨ï¼ŒåŠ è½½CNæ–‡ä»¶ï¼š{abs_path_cn}")
            except Exception as e:
                raise Exception(f"EN/CNæ–‡ä»¶å‡åŠ è½½å¤±è´¥ï¼š{e}")
        else:
            raise Exception(f"ä¸»æ–‡ä»¶åŠ è½½å¤±è´¥ï¼š{e}")
    except Exception as e:
        raise Exception(f"è¯»å–æ–‡ä»¶å¼‚å¸¸ï¼š{e}")

    # æ£€æµ‹ç©ºæ•°æ®
    if not dict_rows_now:
        raise ValueError(f"ä¸»CSVæ–‡ä»¶è¯»å–åæ— æœ‰æ•ˆæ•°æ®ï¼š{abs_file_path}")
    if not dict_rows_other:
        raise ValueError(f"å¤‡ç”¨CSVæ–‡ä»¶ï¼ˆEN/CNï¼‰è¯»å–åæ— æœ‰æ•ˆæ•°æ®ï¼š{abs_path_en if not EN_to_CN else abs_path_cn}")

    # æå–æœ‰æ•ˆIDï¼ˆæ’é™¤æ³¨é‡Š/ç©ºIDï¼‰
    valid_ids_now = {
        row['id'].strip() for row in dict_rows_now
        if row.get('id', '').strip() and not row['id'].strip().startswith('#')
    }
    valid_ids_other = {
        row['id'].strip() for row in dict_rows_other
        if row.get('id', '').strip() and not row['id'].strip().startswith('#')
    }
    common_ids = valid_ids_now.intersection(valid_ids_other)
    print(f"ğŸ” æ‰¾åˆ°å¯äº¤æ¢çš„å…¬å…±IDæ•°é‡ï¼š{len(common_ids)}")

    # äº¤æ¢æŒ‡å®šå­—æ®µçš„å€¼
    for common_id in common_ids:
        # æ‰¾åˆ°å¯¹åº”IDçš„è¡Œ
        row_now = next((r for r in dict_rows_now if r['id'].strip() == common_id), None)
        row_other = next((r for r in dict_rows_other if r['id'].strip() == common_id), None)
        if not row_now or not row_other:
            continue

        # é€å­—æ®µäº¤æ¢
        for field in swap_fields:
            try:
                # è·³è¿‡ä¸å­˜åœ¨çš„å­—æ®µ
                if field not in row_now or field not in row_other:
                    print(f"âš ï¸ å­—æ®µ{field}åœ¨ID{common_id}ä¸­ä¸å­˜åœ¨ï¼Œè·³è¿‡")
                    continue

                # ä¿ç•™åŸå§‹å€¼ï¼ˆå«ä¸­æ–‡é€—å·ï¼‰ï¼Œä»…äº¤æ¢å€¼
                val_now = row_now[field]
                val_other = row_other[field]

                # å¤„ç†å­—æ®µå†…çš„JSONæ ¼å¼å€¼ï¼ˆä¿ç•™ä¸­æ–‡é€—å·ï¼‰
                if val_now and val_other and val_now.startswith("{") and val_now.endswith("}") and val_other.startswith("{") and val_other.endswith("}"):
                    val_now = json.loads(clean_json_content(val_now))
                    val_other = json.loads(clean_json_content(val_other))

                # äº¤æ¢å€¼ï¼ˆä¿ç•™æ‰€æœ‰å­—ç¬¦ï¼ŒåŒ…æ‹¬ä¸­æ–‡é€—å·ï¼‰
                row_now[field] = str(val_other) if isinstance(val_other, (dict, list)) else val_other
                row_other[field] = str(val_now) if isinstance(val_now, (dict, list)) else val_now

            except Exception as e:
                raise Exception(f"ID{common_id}å­—æ®µ{field}äº¤æ¢å¤±è´¥ï¼š{e}")

    # å†™å…¥ä¸»æ–‡ä»¶åˆ°ä¸´æ—¶æ–‡ä»¶
    try:
        temp_main_path = write_to_temp_csv(dict_rows_now, abs_file_path)
        print(f"ğŸ“ ä¸»æ–‡ä»¶ä¸´æ—¶æ–‡ä»¶ç”Ÿæˆï¼š{temp_main_path}")
    except Exception as e:
        raise Exception(f"ä¸»æ–‡ä»¶ä¸´æ—¶æ–‡ä»¶å†™å…¥å¤±è´¥ï¼š{e}")

    # å†™å…¥å¤‡ä»½æ–‡ä»¶åˆ°ä¸´æ—¶æ–‡ä»¶
    try:
        target_path = abs_path_en if EN_to_CN else abs_path_cn
        temp_backup_path = write_to_temp_csv(dict_rows_other, target_path)
        print(f"ğŸ“ å¤‡ä»½æ–‡ä»¶ä¸´æ—¶æ–‡ä»¶ç”Ÿæˆï¼š{temp_backup_path}")
    except Exception as e:
        raise Exception(f"å¤‡ä»½æ–‡ä»¶ä¸´æ—¶æ–‡ä»¶å†™å…¥å¤±è´¥ï¼š{e}")

# -------------------------- JSONæ–‡ä»¶äº¤æ¢é€»è¾‘ --------------------------
def swap_json(file_path: str, file_name_without_extension: str, extension: str = None) -> None:
    """
    å¤„ç†JSON/factionæ–‡ä»¶äº¤æ¢ï¼ˆä»…å†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼Œä¸ç«‹å³æ›¿æ¢åŸæ–‡ä»¶ï¼‰ï¼š
    1. ä¿ç•™å­—ç¬¦ä¸²å†…çš„ä¸­æ–‡é€—å·
    2. é€’å½’äº¤æ¢JSONå†…çš„å¯¹åº”å€¼
    """
    # å¤„ç†è·¯å¾„
    abs_file_path = get_abs_file_path(file_path)
    script_dir = os.path.dirname(abs_file_path)
    file_ext = extension if extension else os.path.splitext(abs_file_path)[1].lstrip('.')

    # æ„å»ºEN/CNæ–‡ä»¶è·¯å¾„
    en_file_name = f"{file_name_without_extension}_EN.{file_ext}"
    cn_file_name = f"{file_name_without_extension}_CN.{file_ext}"
    abs_path_en = os.path.join(script_dir, en_file_name)
    abs_path_cn = os.path.join(script_dir, cn_file_name)

    # ä¿®æ­£è·¯å¾„æ›¿æ¢é€»è¾‘
    if file_name_without_extension in abs_file_path:
        abs_path_en = abs_file_path.replace(file_name_without_extension, f"{file_name_without_extension}_EN")
        abs_path_cn = abs_file_path.replace(file_name_without_extension, f"{file_name_without_extension}_CN")

    EN_to_CN = False
    data1 = None  # ä¸»æ–‡ä»¶æ•°æ®
    data2 = None  # å¤‡ä»½æ–‡ä»¶æ•°æ®

    # è¯»å–ä¸»æ–‡ä»¶ + å¤‡ä»½æ–‡ä»¶ï¼ˆä¿ç•™ä¸­æ–‡é€—å·ï¼‰
    try:
        data1 = read_json_safely(abs_file_path)
        data2 = read_json_safely(abs_path_en)
        print(f"ğŸ“„ åŠ è½½ä¸»æ–‡ä»¶+ENæ–‡ä»¶ï¼š{abs_file_path} + {abs_path_en}")
    except FileNotFoundError as e:
        if en_file_name in str(e):
            EN_to_CN = True
            try:
                data2 = read_json_safely(abs_path_cn)
                print(f"ğŸ“„ ENæ–‡ä»¶ä¸å­˜åœ¨ï¼ŒåŠ è½½CNæ–‡ä»¶ï¼š{abs_path_cn}")
            except Exception as e:
                raise Exception(f"EN/CNæ–‡ä»¶å‡åŠ è½½å¤±è´¥ï¼š{e}")
        else:
            raise Exception(f"ä¸»æ–‡ä»¶åŠ è½½å¤±è´¥ï¼š{e}")
    except Exception as e:
        raise Exception(f"JSONè¯»å–å¼‚å¸¸ï¼š{e}")

    # æ–°å¢ï¼šç©ºæ•°æ®æœ€ç»ˆæ ¡éªŒï¼ˆåŒé‡ä¿éšœï¼‰
    if data1 is None or not data1:
        raise ValueError(f"ä¸»JSONæ–‡ä»¶æ— æœ‰æ•ˆæ•°æ®ï¼š{abs_file_path}")
    if data2 is None or not data2:
        raise ValueError(f"å¤‡ç”¨JSONæ–‡ä»¶æ— æœ‰æ•ˆæ•°æ®ï¼š{abs_path_en if not EN_to_CN else abs_path_cn}")

    # é€’å½’äº¤æ¢JSONå€¼ï¼ˆä¿ç•™ä¸­æ–‡é€—å·ï¼Œä»…äº¤æ¢å¯¹åº”å€¼ï¼‰
    def swap_nested_json_values(data1: Union[Dict, List], data2: Union[Dict, List]):
        if isinstance(data1, dict) and isinstance(data2, dict):
            # åªäº¤æ¢åŒæ–¹éƒ½æœ‰çš„key
            common_keys = set(data1.keys()).intersection(data2.keys())
            for key in common_keys:
                if isinstance(data1[key], (dict, list)) and isinstance(data2[key], (dict, list)):
                    swap_nested_json_values(data1[key], data2[key])
                else:
                    # åŸºç¡€ç±»å‹äº¤æ¢ï¼ˆä¿ç•™æ‰€æœ‰å­—ç¬¦ï¼ŒåŒ…æ‹¬ä¸­æ–‡é€—å·ï¼‰
                    temp = cp.deepcopy(data2[key])
                    data2[key] = cp.deepcopy(data1[key])
                    data1[key] = temp
        elif isinstance(data1, list) and isinstance(data2, list):
            # æ•°ç»„æŒ‰ç´¢å¼•äº¤æ¢ï¼ˆä»…å½“é•¿åº¦ä¸€è‡´æ—¶ï¼‰
            min_len = min(len(data1), len(data2))
            for i in range(min_len):
                if isinstance(data1[i], (dict, list)) and isinstance(data2[i], (dict, list)):
                    swap_nested_json_values(data1[i], data2[i])
                else:
                    temp = cp.deepcopy(data2[i])
                    data2[i] = cp.deepcopy(data1[i])
                    data1[i] = temp

    # æ‰§è¡Œäº¤æ¢
    swap_nested_json_values(data1, data2)

    # å†™å…¥ä¸»æ–‡ä»¶åˆ°ä¸´æ—¶æ–‡ä»¶
    try:
        temp_main_path = write_to_temp_json(data1, abs_file_path)
        print(f"ğŸ“ ä¸»æ–‡ä»¶ä¸´æ—¶æ–‡ä»¶ç”Ÿæˆï¼š{temp_main_path}")
    except Exception as e:
        raise Exception(f"ä¸»æ–‡ä»¶ä¸´æ—¶æ–‡ä»¶å†™å…¥å¤±è´¥ï¼š{e}")

    # å†™å…¥å¤‡ä»½æ–‡ä»¶åˆ°ä¸´æ—¶æ–‡ä»¶
    try:
        target_path = abs_path_en if EN_to_CN else abs_path_cn
        temp_backup_path = write_to_temp_json(data2, target_path)
        print(f"ğŸ“ å¤‡ä»½æ–‡ä»¶ä¸´æ—¶æ–‡ä»¶ç”Ÿæˆï¼š{temp_backup_path}")
    except Exception as e:
        raise Exception(f"å¤‡ä»½æ–‡ä»¶ä¸´æ—¶æ–‡ä»¶å†™å…¥å¤±è´¥ï¼š{e}")

# -------------------------- æ–‡ä»¶é‡å‘½åé€»è¾‘ --------------------------
def swap_name(file_path: str, file_name_with_ext: str) -> None:
    """é¢„æ”¶é›†é‡å‘½åä»»åŠ¡ï¼Œä¸ç«‹å³æ‰§è¡Œé‡å‘½å"""
    abs_file_path = get_abs_file_path(file_path)
    file_dir = os.path.dirname(abs_file_path)
    base_name, ext = os.path.splitext(file_name_with_ext)

    # æ„å»ºCN/ENæ–‡ä»¶å
    cn_file = f"{base_name}_CN{ext}"
    en_file = f"{base_name}_EN{ext}"
    cn_path = os.path.join(file_dir, cn_file)
    en_path = os.path.join(file_dir, en_file)

    # If both exist, decide based on settings
    if os.path.exists(cn_path) and os.path.exists(en_path):
        # Try to read settings to determine current language
        try:
            settings_path = get_abs_file_path('data/config/settings.json')
            settings = read_json_safely(settings_path)
            use_en = bool(settings.get('aEP_UseEnString', False))
            print(f"ğŸ“˜ æ£€æµ‹åˆ°åŒæ–¹åç¼€å‡å­˜åœ¨ï¼Œé…ç½® aEP_UseEnString={use_en}ï¼ˆTrue=ENï¼‰")
            if use_en:
                # Currently EN: treat as if EN exists only -> original -> CN, EN -> original
                RENAME_TASKS.append((abs_file_path, cn_path, en_path))
                print(f"ğŸ“Œ é¢„æ”¶é›†é‡å‘½åä»»åŠ¡ï¼ˆåŸºäºè®¾ç½®=ENï¼‰ï¼š{abs_file_path} â†” {en_path}")
            else:
                # Currently CN: treat as if CN exists only -> original -> EN, CN -> original
                RENAME_TASKS.append((abs_file_path, en_path, cn_path))
                print(f"ğŸ“Œ é¢„æ”¶é›†é‡å‘½åä»»åŠ¡ï¼ˆåŸºäºè®¾ç½®=CNï¼‰ï¼š{abs_file_path} â†” {cn_path}")
            return
        except FileNotFoundError:
            print("âš ï¸ è®¾ç½®æ–‡ä»¶ data/config/settings.json æœªæ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤åç¼€ä¼˜å…ˆç­–ç•¥ï¼ˆCNä¼˜å…ˆï¼‰")
        except Exception as e:
            print(f"âš ï¸ è¯»å–è®¾ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤åç¼€ä¼˜å…ˆç­–ç•¥ï¼š{e}")

    # æ”¶é›†é‡å‘½åä»»åŠ¡ï¼ˆåŸæ–‡ä»¶, ç›®æ ‡æ–‡ä»¶1, ç›®æ ‡æ–‡ä»¶2ï¼‰
    if os.path.exists(cn_path):
        # åŸæ–‡ä»¶ â†’ ENæ–‡ä»¶ï¼ŒCNæ–‡ä»¶ â†’ åŸæ–‡ä»¶
        RENAME_TASKS.append((abs_file_path, en_path, cn_path))
        print(f"ğŸ“Œ é¢„æ”¶é›†é‡å‘½åä»»åŠ¡ï¼š{abs_file_path} â†” {cn_file}")
    elif os.path.exists(en_path):
        # åŸæ–‡ä»¶ â†’ CNæ–‡ä»¶ï¼ŒENæ–‡ä»¶ â†’ åŸæ–‡ä»¶
        RENAME_TASKS.append((abs_file_path, cn_path, en_path))
        print(f"ğŸ“Œ é¢„æ”¶é›†é‡å‘½åä»»åŠ¡ï¼š{abs_file_path} â†” {en_file}")
    else:
        raise Exception(f"æœªæ‰¾åˆ°å¯¹åº”çš„CN/ENæ–‡ä»¶ï¼š{cn_path} / {en_path}")

def batch_execute_rename() -> None:
    """æ‰¹é‡æ‰§è¡Œé‡å‘½åä»»åŠ¡ï¼Œä¿è¯åŸå­æ€§

    è¡Œä¸ºè¯´æ˜ï¼š
    - å¯¹äºæ¯ä¸ªé‡å‘½åä»»åŠ¡ (original_path, temp_path, swap_path)ï¼š
      1. å°† original_path ç§»åˆ° temp_pathï¼ˆä¿å­˜åŸå§‹å†…å®¹åˆ°å¸¦åç¼€æ–‡ä»¶ï¼‰
      2. å°† swap_path ç§»åˆ° original_pathï¼ˆæŠŠäº¤æ¢è¿‡æ¥çš„å†…å®¹æ”¾å›åŸä½ç½®ï¼‰
      3. åœ¨åŒç›®å½•ä¸‹æ¸…ç†é™¤ temp_path ä»¥å¤–çš„ *_EN/*_CN æ–‡ä»¶ï¼Œåªä¿ç•™ temp_pathï¼ˆå³ä¿å­˜è¢«æ¢å‡ºçš„å‰¯æœ¬ï¼‰å’Œæœ€ç»ˆçš„ original_path
    """
    for original_path, temp_path, swap_path in RENAME_TASKS:
        tmp_backup = None
        try:
            file_dir = os.path.dirname(original_path)
            base_name = os.path.splitext(os.path.basename(original_path))[0]
            ext = os.path.splitext(original_path)[1]

            # If temp_path already exists, move original to a unique tmp backup first
            if os.path.exists(temp_path):
                # create unique temporary path in the same dir
                fd, tmp_backup = tempfile.mkstemp(prefix=base_name + '_orig_backup_', suffix=ext, dir=file_dir)
                os.close(fd)
                # remove the zero-length file created by mkstemp so os.rename can use the name
                os.remove(tmp_backup)
                # move original -> tmp_backup
                os.rename(original_path, tmp_backup)
            else:
                # safe to move original -> temp_path directly
                os.rename(original_path, temp_path)

            # move swap_path -> original_path (replace if exists)
            # use os.replace to overwrite if necessary
            os.replace(swap_path, original_path)
            print(f"âœ… æ‰¹é‡é‡å‘½åå®Œæˆï¼š{original_path} â†” {swap_path}")

            # if we used tmp_backup, now move it to temp_path (overwriting existing temp_path if any)
            if tmp_backup:
                try:
                    if os.path.exists(temp_path):
                        os.remove(temp_path)
                    os.rename(tmp_backup, temp_path)
                except Exception as de:
                    print(f"âš ï¸ æ— æ³•å°†ä¸´æ—¶å¤‡ä»½ç§»åŠ¨åˆ°ç›®æ ‡åç¼€ä½ç½®ï¼š{de}")

            # Step 3: æ¸…ç†åŒç›®å½•ä¸‹çš„ *_EN/*_CN æ–‡ä»¶ï¼Œä¿ç•™ temp_pathï¼ˆè¢«æ¢å‡ºçš„å‰¯æœ¬ï¼‰
            try:
                candidates = [
                    os.path.join(file_dir, f"{base_name}_EN{ext}"),
                    os.path.join(file_dir, f"{base_name}_CN{ext}")
                ]
                for candidate in candidates:
                    # if candidate exists but is not the temp_path we want to keep, delete it
                    if os.path.exists(candidate):
                        # normalize paths for comparison
                        cand_norm = os.path.normcase(os.path.abspath(candidate))
                        keep_norm = os.path.normcase(os.path.abspath(temp_path))
                        orig_norm = os.path.normcase(os.path.abspath(original_path))
                        if cand_norm != keep_norm and cand_norm != orig_norm:
                            try:
                                os.remove(candidate)
                                print(f"ğŸ—‘ï¸ å·²åˆ é™¤é¢å¤–çš„åç¼€æ–‡ä»¶ï¼š{candidate}")
                            except Exception as de:
                                print(f"âš ï¸ æ— æ³•åˆ é™¤æ–‡ä»¶ {candidate}ï¼š{de}")
                        else:
                            print(f"â„¹ï¸ ä¿ç•™åç¼€æ–‡ä»¶ï¼š{candidate}")
            except Exception as de:
                print(f"âš ï¸ æ¸…ç†åç¼€æ–‡ä»¶æ—¶å‡ºé”™ï¼š{de}")

        except Exception as e:
            print(f"âš ï¸ æ‰¹é‡é‡å‘½åå¤±è´¥ {original_path}ï¼š{e}")
            # attempt to cleanup tmp_backup if exists
            try:
                if tmp_backup and os.path.exists(tmp_backup):
                    os.remove(tmp_backup)
            except Exception:
                pass
            raise
    # æ¸…ç©ºé‡å‘½åä»»åŠ¡åˆ—è¡¨
    RENAME_TASKS.clear()

# -------------------------- JSONé…ç½®æ›´æ–°é€»è¾‘ --------------------------
def update_setting_in_json(file_path: str, key: str, new_value: Any = None) -> None:
    """æ›´æ–°JSONé…ç½®ï¼ˆä¿ç•™ä¸­æ–‡é€—å·ï¼Œå†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼‰"""
    abs_file_path = get_abs_file_path(file_path)
    try:
        # å®‰å…¨è¯»å–ï¼ˆä¿ç•™ä¸­æ–‡é€—å·ï¼‰
        with open(abs_file_path, 'r', encoding='utf-8-sig') as f:
            raw_content = f.read()
        clean_content = clean_json_content(raw_content)

        # æ£€æµ‹ç©ºå†…å®¹
        if not clean_content:
            raise ValueError(f"é…ç½®æ–‡ä»¶æ¸…ç†åæ— æœ‰æ•ˆå†…å®¹ï¼š{abs_file_path}")

        settings = json.loads(clean_content)

        # æ£€æµ‹ç©ºé…ç½®
        if not settings:
            raise ValueError(f"é…ç½®æ–‡ä»¶è§£æåä¸ºç©ºï¼š{abs_file_path}")

        # æ›´æ–°é…ç½®
        if key in settings:
            if new_value is None:
                # å¸ƒå°”å€¼å–å
                if not isinstance(settings[key], bool):
                    raise ValueError(f"é”®{key}ä¸æ˜¯å¸ƒå°”å€¼ï¼Œæ— æ³•å–åï¼ˆå½“å‰å€¼ï¼š{settings[key]}ï¼Œç±»å‹ï¼š{type(settings[key])}ï¼‰")
                settings[key] = not settings[key]
            else:
                settings[key] = new_value
            print(f"ğŸ”§ æ›´æ–°é…ç½®ï¼š{key} = {settings[key]}")
        else:
            raise KeyError(f"é”®{key}ä¸å­˜åœ¨äºé…ç½®æ–‡ä»¶ä¸­ï¼ˆå¯ç”¨é”®ï¼š{list(settings.keys())}ï¼‰")

        # å†™å…¥ä¸´æ—¶æ–‡ä»¶
        temp_config_path = write_to_temp_json(settings, abs_file_path)
        print(f"ğŸ“ é…ç½®æ–‡ä»¶ä¸´æ—¶æ–‡ä»¶ç”Ÿæˆï¼š{temp_config_path}")
    except FileNotFoundError:
        raise Exception(f"é…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼š{abs_file_path}")
    except json.JSONDecodeError:
        raise Exception(f"é…ç½®æ–‡ä»¶JSONè§£æå¤±è´¥ï¼š{abs_file_path}")
    except Exception as e:
        raise Exception(f"é…ç½®æ›´æ–°å¼‚å¸¸ï¼š{e}")

# -------------------------- ä¸»æ‰§è¡Œé€»è¾‘ï¼ˆåŸå­æ€§æ‰¹é‡å¤„ç†ï¼‰ --------------------------
if __name__ == "__main__":
    try:
        # ========== ç¬¬ä¸€æ­¥ï¼šæ‰¹é‡å¤„ç†æ‰€æœ‰æ–‡ä»¶ï¼Œç”Ÿæˆä¸´æ—¶æ–‡ä»¶/æ”¶é›†é‡å‘½åä»»åŠ¡ ==========
        print("=== å¼€å§‹å¤„ç†æ‰€æœ‰æ–‡ä»¶ï¼Œç”Ÿæˆä¸´æ—¶æ–‡ä»¶ ===")

        # CSVæ–‡ä»¶äº¤æ¢ï¼ˆç”Ÿæˆä¸´æ—¶æ–‡ä»¶ï¼‰
        swap_file_csv("data/campaign/submarkets.csv", "submarkets", ['name', 'desc'])
        swap_file_csv("data/campaign/rules.csv", "rules", ['script','text','options'])
        swap_file_csv("data/campaign/industries.csv", "industries", ['name','desc'])
        swap_file_csv("data/campaign/special_items.csv", "special_items", ['name','tech/manufacturer','desc'])
        swap_file_csv("data/campaign/commodities.csv", "commodities", ['name'])
        swap_file_csv("data/campaign/market_conditions.csv", "market_conditions", ['name','desc'])
        swap_file_csv("data/strings/descriptions.csv", "descriptions", ['text1','text2','text3','text4','text5'])
        swap_file_csv("data/characters/skills/skill_data.csv", "skill_data", ['name','description','author'])
        swap_file_csv("data/shipsystems/ship_systems.csv", "ship_systems", ['name'])
        swap_file_csv("data/hulls/ship_data.csv", "ship_data", ['name','tech/manufacturer','designation'])
        swap_file_csv("data/hullmods/hull_mods.csv","hull_mods",['name','tech/manufacturer','uiTags','desc','short','sModDesc'])
        swap_file_csv("data/weapons/weapon_data.csv","weapon_data",['name','tech/manufacturer','primaryRoleStr','customPrimary'])
        swap_file_csv("data/config/LunaSettings.csv", "LunaSettings", ['fieldName','fieldDescription' ])

        # æ–‡ä»¶é‡å‘½åï¼ˆé¢„æ”¶é›†ä»»åŠ¡ï¼‰
        swap_name("data/missions/aEP_eliminate_mission/descriptor.json", "descriptor.json")
        swap_name("data/missions/aEP_eliminate_mission/mission_text.txt", "mission_text.txt")
        swap_name("data/missions/aEP_first_contact/descriptor.json", "descriptor.json")
        swap_name("data/missions/aEP_first_contact/mission_text.txt", "mission_text.txt")
        swap_name("data/missions/aEP_planet_investigation/descriptor.json", "descriptor.json")
        swap_name("data/missions/aEP_planet_investigation/mission_text.txt", "mission_text.txt")
        swap_name("data/missions/aEP_assassination/descriptor.json", "descriptor.json")
        swap_name("data/missions/aEP_assassination/mission_text.txt", "mission_text.txt")

        # JSON/factionæ–‡ä»¶äº¤æ¢ï¼ˆç”Ÿæˆä¸´æ—¶æ–‡ä»¶ï¼‰
        swap_json("mod_info.json","mod_info")
        swap_json("data/config/modFiles/magicBounty_data.json", "magicBounty_data")
        swap_json("data/world/factions/aEP_FSF.faction", "aEP_FSF","faction")
        swap_json("data/world/factions/aEP_FSF_adv.faction", "aEP_FSF_adv","faction")

        # é…ç½®æ›´æ–°ï¼ˆç”Ÿæˆä¸´æ—¶æ–‡ä»¶ï¼‰
        update_setting_in_json("data/config/settings.json", 'aEP_UseEnString', None)

        # ========== ç¬¬äºŒæ­¥ï¼šæ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæˆï¼Œæ‰¹é‡æ‰§è¡Œæ›¿æ¢/é‡å‘½å ==========
        print("\n=== æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶ç”Ÿæˆå®Œæˆï¼Œå¼€å§‹æ‰¹é‡æ›¿æ¢åŸæ–‡ä»¶ ===")
        # æ‰¹é‡æ›¿æ¢ä¸´æ—¶æ–‡ä»¶ä¸ºåŸæ–‡ä»¶
        batch_replace_original_files()
        # æ‰¹é‡æ‰§è¡Œé‡å‘½åä»»åŠ¡
        batch_execute_rename()

        print("\nğŸ‰ æ‰€æœ‰æ–‡ä»¶äº¤æ¢/é‡å‘½åå®Œæˆï¼")

    except Exception as e:
        # ä»»æ„æ­¥éª¤å¤±è´¥ï¼Œæ¸…ç†æ‰€æœ‰ä¸´æ—¶æ–‡ä»¶ï¼Œç»ˆæ­¢æ“ä½œ
        print(f"\nâŒ å¤„ç†å¤±è´¥ï¼š{e}")
        print("ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
        clean_temp_files()
        exit(1)

    # æœ€åæ¸…ç†ç©ºçš„ä¸´æ—¶æ–‡ä»¶åˆ—è¡¨ï¼ˆå†—ä½™ä¿æŠ¤ï¼‰
    clean_temp_files()